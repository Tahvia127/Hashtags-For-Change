{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d22652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f749b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded africa_acled: 255889 rows\n",
      "Loaded asia_pacific_acled: 198169 rows\n",
      "Loaded europe_acled: 110481 rows\n",
      "Loaded latin_america_acled: 161259 rows\n",
      "Loaded middle_east_acled: 137579 rows\n",
      "Loaded us_canada_acled: 20839 rows\n",
      "Combined dataset: 884216 total rows\n"
     ]
    }
   ],
   "source": [
    "# read in ACLED data\n",
    "\n",
    "regions = {\n",
    "    \"africa_acled\": \"data/Africa_aggregated_data_up_to-2025-10-18.csv\",\n",
    "    \"asia_pacific_acled\": \"data/Asia-Pacific_aggregated_data_up_to-2025-10-18.csv\",\n",
    "    \"europe_acled\": \"data/Europe-Central-Asia_aggregated_data_up_to-2025-10-18.csv\",\n",
    "    \"latin_america_acled\": \"data/Latin-America-the-Caribbean_aggregated_data_up_to-2025-10-18.csv\",\n",
    "    \"middle_east_acled\": \"data/Middle-East_aggregated_data_up_to-2025-10-18.csv\",\n",
    "    \"us_canada_acled\": \"data/US-and-Canada_aggregated_data_up_to-2025-10-18.csv\"\n",
    "}\n",
    "\n",
    "# combine datasets\n",
    "dfs = {}\n",
    "for region_name, file_path in regions.items():\n",
    "    dfs[region_name] = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {region_name}: {len(dfs[region_name])} rows\")\n",
    "\n",
    "# Combine into single dataframe\n",
    "acled = pd.concat(dfs.values(), ignore_index=True)\n",
    "print(f\"Combined dataset: {len(acled)} total rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021bfba",
   "metadata": {},
   "source": [
    "## Tier 3 - Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3e171",
   "metadata": {},
   "source": [
    "### I. Country-specific Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73830388",
   "metadata": {},
   "source": [
    "#### 1) Palestine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5dee150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PALESTINE HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 118 months\n",
      "  Date range: 2015-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 27,743\n",
      "  Total fatalities: 22,882\n",
      "\n",
      "NOTE: Hashtag removed for GazaCeasefire due to no data.\n",
      "  ✓ Loaded: #FreePalestine            - 70 months, max=100\n",
      "  ✓ Loaded: #Gaza                     - 70 months, max=100\n",
      "  ✓ Loaded: #GazaCeasefire            - 70 months, max=100\n",
      "  ✓ Loaded: #FreeGaza                 - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 118 months with 4 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "   Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "         #Gaza        0.625221            0.831157           69\n",
      "     #FreeGaza        0.413921            0.685147           69\n",
      "#FreePalestine        0.411616            0.425717           69\n",
      "#GazaCeasefire       -0.054704           -0.044126           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#Gaza:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.630\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.630\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.624\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.625\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.624\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.630\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.630\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#FreeGaza:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.426\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.426\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.415\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.414\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.415\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.426\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.426\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#FreePalestine:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.431\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.433\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.412\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.412\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.412\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.433\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.431\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "October 2023:\n",
      "  ACLED Events: 1,500\n",
      "  ACLED Fatalities: 5,291\n",
      "  Search Interest:\n",
      "    - #FreePalestine           : 51/100\n",
      "    - #Gaza                    : 100/100\n",
      "    - #GazaCeasefire           : 0/100\n",
      "    - #FreeGaza                : 100/100\n",
      "\n",
      "December 2023:\n",
      "  ACLED Events: 967\n",
      "  ACLED Fatalities: 2,487\n",
      "  Search Interest:\n",
      "    - #FreePalestine           : 31/100\n",
      "    - #Gaza                    : 22/100\n",
      "    - #GazaCeasefire           : 0/100\n",
      "    - #FreeGaza                : 0/100\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 943\n",
      "  ACLED Fatalities: 966\n",
      "  Search Interest:\n",
      "    - #FreePalestine           : 10/100\n",
      "    - #Gaza                    : 11/100\n",
      "    - #GazaCeasefire           : 0/100\n",
      "    - #FreeGaza                : 0/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 844\n",
      "  ACLED Fatalities: 1,312\n",
      "  Search Interest:\n",
      "    - #FreePalestine           : 10/100\n",
      "    - #Gaza                    : 8/100\n",
      "    - #GazaCeasefire           : 0/100\n",
      "    - #FreeGaza                : 0/100\n",
      "\n",
      "June 2024:\n",
      "  ACLED Events: 829\n",
      "  ACLED Fatalities: 1,074\n",
      "  Search Interest:\n",
      "    - #FreePalestine           : 34/100\n",
      "    - #Gaza                    : 11/100\n",
      "    - #GazaCeasefire           : 0/100\n",
      "    - #FreeGaza                : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: palestine_hashtags_acled_vs_trends.html\n",
      "✓ Saved: palestine_hashtags_#gaza_comparison.html\n",
      "✓ Saved: palestine_hashtags_#freegaza_comparison.html\n",
      "✓ Saved: palestine_hashtags_#freepalestine_comparison.html\n",
      "\n",
      "✓ Palestine Hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# PALESTINE HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PALESTINE HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "palestine_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Palestine') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "palestine_acled['WEEK'] = pd.to_datetime(palestine_acled['WEEK'])\n",
    "\n",
    "palestine_acled['month'] = palestine_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = palestine_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "palestine_hashtag_files = {\n",
    "    '#FreePalestine': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FreePalestine.csv',\n",
    "    '#Gaza': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Gaza.csv',\n",
    "    '#GazaCeasefire': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_GazaCeasefire.csv',\n",
    "    '#FreeGaza': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FreeGaza.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtag removed for GazaCeasefire due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in palestine_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Palestine Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Palestine-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('palestine_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: palestine_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Palestine Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"palestine_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Palestine Hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696ad4f",
   "metadata": {},
   "source": [
    "#### 2) Ukraine/Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0b60ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UKRAINE-RUSSIA HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 94 months\n",
      "  Date range: 2017-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 106,598\n",
      "  Total fatalities: 74,494\n",
      "  ✓ Loaded: #UkraineWar               - 70 months, max=100\n",
      "  ✓ Loaded: #StandWithUkraine         - 70 months, max=100\n",
      "  ✓ Loaded: #SlavaUkraine             - 70 months, max=100\n",
      "  ✓ Loaded: #RussiaUkraineWar         - 70 months, max=100\n",
      "  ✓ Loaded: #StopPutin                - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 94 months with 5 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "      Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#StandWithUkraine        0.032669            0.011247           69\n",
      "#RussiaUkraineWar        0.019567            0.005528           69\n",
      "      #UkraineWar        0.014349            0.024689           69\n",
      "    #SlavaUkraine       -0.075668           -0.065052           69\n",
      "       #StopPutin       -0.099928           -0.056665           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#StandWithUkraine:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.045\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.046\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.029\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.033\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.029\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.046\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.045\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#RussiaUkraineWar:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.025\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.026\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.018\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.020\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.018\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.026\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.025\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#UkraineWar:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.023\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.025\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.011\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.014\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.011\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.025\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.023\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 3,907\n",
      "  ACLED Fatalities: 2,741\n",
      "  Search Interest:\n",
      "    - #UkraineWar              : 0/100\n",
      "    - #StandWithUkraine        : 0/100\n",
      "    - #SlavaUkraine            : 0/100\n",
      "    - #RussiaUkraineWar        : 0/100\n",
      "    - #StopPutin               : 0/100\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 3,872\n",
      "  ACLED Fatalities: 2,195\n",
      "  Search Interest:\n",
      "    - #UkraineWar              : 0/100\n",
      "    - #StandWithUkraine        : 0/100\n",
      "    - #SlavaUkraine            : 0/100\n",
      "    - #RussiaUkraineWar        : 0/100\n",
      "    - #StopPutin               : 0/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 3,772\n",
      "  ACLED Fatalities: 2,679\n",
      "  Search Interest:\n",
      "    - #UkraineWar              : 9/100\n",
      "    - #StandWithUkraine        : 0/100\n",
      "    - #SlavaUkraine            : 0/100\n",
      "    - #RussiaUkraineWar        : 0/100\n",
      "    - #StopPutin               : 0/100\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 3,500\n",
      "  ACLED Fatalities: 3,561\n",
      "  Search Interest:\n",
      "    - #UkraineWar              : 0/100\n",
      "    - #StandWithUkraine        : 0/100\n",
      "    - #SlavaUkraine            : 0/100\n",
      "    - #RussiaUkraineWar        : 0/100\n",
      "    - #StopPutin               : 0/100\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 3,438\n",
      "  ACLED Fatalities: 3,686\n",
      "  Search Interest:\n",
      "    - #UkraineWar              : 0/100\n",
      "    - #StandWithUkraine        : 3/100\n",
      "    - #SlavaUkraine            : 0/100\n",
      "    - #RussiaUkraineWar        : 0/100\n",
      "    - #StopPutin               : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: ukraineRussia_hashtags_acled_vs_trends.html\n",
      "✓ Saved: ukraineRussia_hashtags_#standwithukraine_comparison.html\n",
      "✓ Saved: ukraineRussia_hashtags_#russiaukrainewar_comparison.html\n",
      "✓ Saved: ukraineRussia_hashtags_#ukrainewar_comparison.html\n",
      "\n",
      "✓ Ukraine-Russia hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# UKRAINE-RUSSIA ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UKRAINE-RUSSIA HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "ukraineRussia_acled = acled[\n",
    "    ((acled['COUNTRY'] == 'Ukraine') | (acled['COUNTRY'] == 'Russia')) & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "ukraineRussia_acled['WEEK'] = pd.to_datetime(ukraineRussia_acled['WEEK'])\n",
    "\n",
    "ukraineRussia_acled['month'] = ukraineRussia_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = ukraineRussia_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "ukraineRussia_hashtag_files = {\n",
    "    '#UkraineWar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_UkraineWar.csv',\n",
    "    '#StandWithUkraine': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StandWithUkraine.csv',\n",
    "    '#SlavaUkraine': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_SlavaUkraine.csv',\n",
    "    '#RussiaUkraineWar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_RussiaUkraineWar.csv',\n",
    "    '#StopPutin': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StopPutin.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in ukraineRussia_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Ukraine & Russia: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Ukraine & Russia-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('ukraineRussia_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: ukraineRussia_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Ukraine-Russia Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"ukraineRussia_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Ukraine-Russia hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6cbce",
   "metadata": {},
   "source": [
    "#### 3) Syria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd5f14a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SYRIA HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 106 months\n",
      "  Date range: 2016-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 50,064\n",
      "  Total fatalities: 46,791\n",
      "  ✓ Loaded: #SyriaWar                 - 70 months, max=100\n",
      "  ✓ Loaded: #Syria                    - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 106 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "     #Syria        0.139592            0.333633           69\n",
      "  #SyriaWar       -0.000538           -0.070622           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#Syria:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.091\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.080\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.136\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.140\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.136\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.080\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.091\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#SyriaWar:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +nan\n",
      "  Lag -2 months (searches LEAD  ): correlation = +nan\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.002\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.001\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.002\n",
      "  Lag +2 months (searches LAG   ): correlation = +nan\n",
      "  Lag +3 months (searches LAG   ): correlation = +nan\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "September 2017:\n",
      "  ACLED Events: 1,483\n",
      "  ACLED Fatalities: 3,107\n",
      "  Search Interest:\n",
      "\n",
      "April 2017:\n",
      "  ACLED Events: 1,458\n",
      "  ACLED Fatalities: 2,513\n",
      "  Search Interest:\n",
      "\n",
      "January 2017:\n",
      "  ACLED Events: 1,376\n",
      "  ACLED Fatalities: 2,179\n",
      "  Search Interest:\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 1,182\n",
      "  ACLED Fatalities: 1,003\n",
      "  Search Interest:\n",
      "    - #SyriaWar                : 0/100\n",
      "    - #Syria                   : 0/100\n",
      "\n",
      "July 2017:\n",
      "  ACLED Events: 1,153\n",
      "  ACLED Fatalities: 1,970\n",
      "  Search Interest:\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: syria_hashtags_acled_vs_trends.html\n",
      "✓ Saved: syria_hashtags_#syria_comparison.html\n",
      "✓ Saved: syria_hashtags_#syriawar_comparison.html\n",
      "\n",
      "✓ Syria hashtags analysis complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# SYRIA HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SYRIA HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "syria_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Syria') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "syria_acled['WEEK'] = pd.to_datetime(syria_acled['WEEK'])\n",
    "\n",
    "syria_acled['month'] = syria_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = syria_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "syria_hashtag_files = {\n",
    "    '#SyriaWar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_SyriaWar.csv',\n",
    "    '#Syria': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Syria.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in syria_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Syria Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Syria-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('syria_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: syria_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Syria Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"syria_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Syria hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abc829",
   "metadata": {},
   "source": [
    "#### 4) Turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "569baff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TURKEY HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 118 months\n",
      "  Date range: 2015-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 16,115\n",
      "  Total fatalities: 3,109\n",
      "  ✓ Loaded: #TurkishWomen             - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 118 months with 1 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "  Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#TurkishWomen       -0.054259            -0.12587           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#TurkishWomen:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.061\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.055\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.058\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.054\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.058\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.055\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.061\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "July 2016:\n",
      "  ACLED Events: 736\n",
      "  ACLED Fatalities: 97\n",
      "  Search Interest:\n",
      "\n",
      "October 2023:\n",
      "  ACLED Events: 373\n",
      "  ACLED Fatalities: 3\n",
      "  Search Interest:\n",
      "    - #TurkishWomen            : 0/100\n",
      "\n",
      "December 2023:\n",
      "  ACLED Events: 363\n",
      "  ACLED Fatalities: 3\n",
      "  Search Interest:\n",
      "    - #TurkishWomen            : 0/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 315\n",
      "  ACLED Fatalities: 0\n",
      "  Search Interest:\n",
      "    - #TurkishWomen            : 0/100\n",
      "\n",
      "June 2024:\n",
      "  ACLED Events: 296\n",
      "  ACLED Fatalities: 1\n",
      "  Search Interest:\n",
      "    - #TurkishWomen            : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: turkey_hashtags_acled_vs_trends.html\n",
      "✓ Saved: turkey_hashtags_#turkishwomen_comparison.html\n",
      "\n",
      "✓ Turkey hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# TURKEY HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TURKEY HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "turkey_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Turkey') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "turkey_acled['WEEK'] = pd.to_datetime(turkey_acled['WEEK'])\n",
    "\n",
    "turkey_acled['month'] = turkey_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = turkey_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "turkey_hashtag_files = {\n",
    "    '#TurkishWomen': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_TurkishWomen.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in turkey_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Turkey Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Turkey-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('turkey_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: turkey_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Turkey Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"turkey_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Turkey hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1a9e8",
   "metadata": {},
   "source": [
    "#### 5) Yemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f999fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "YEMEN HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 130 months\n",
      "  Date range: 2014-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 36,708\n",
      "  Total fatalities: 55,897\n",
      "\n",
      "NOTE: Hashtag removed for TalkAboutYemen due to no data.\n",
      "  ✓ Loaded: #TalkAboutYemen           - 70 months, max=100\n",
      "  ✓ Loaded: #YemenPeace               - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 130 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "    Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "    #YemenPeace        0.134008           -0.007178           69\n",
      "#TalkAboutYemen       -0.056758           -0.116162           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#YemenPeace:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.148\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.140\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.134\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.134\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.134\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.140\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.148\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#TalkAboutYemen:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.049\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.053\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.057\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.057\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.057\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.053\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.049\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "December 2024:\n",
      "  ACLED Events: 749\n",
      "  ACLED Fatalities: 163\n",
      "  Search Interest:\n",
      "    - #TalkAboutYemen          : 0/100\n",
      "    - #YemenPeace              : 0/100\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 647\n",
      "  ACLED Fatalities: 127\n",
      "  Search Interest:\n",
      "    - #TalkAboutYemen          : 0/100\n",
      "    - #YemenPeace              : 0/100\n",
      "\n",
      "March 2019:\n",
      "  ACLED Events: 543\n",
      "  ACLED Fatalities: 1,661\n",
      "  Search Interest:\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 539\n",
      "  ACLED Fatalities: 110\n",
      "  Search Interest:\n",
      "    - #TalkAboutYemen          : 0/100\n",
      "    - #YemenPeace              : 0/100\n",
      "\n",
      "September 2018:\n",
      "  ACLED Events: 531\n",
      "  ACLED Fatalities: 1,498\n",
      "  Search Interest:\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: yemen_hashtags_acled_vs_trends.html\n",
      "✓ Saved: yemen_hashtags_#yemenpeace_comparison.html\n",
      "✓ Saved: yemen_hashtags_#talkaboutyemen_comparison.html\n",
      "\n",
      "✓ Yemen hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# YEMEN HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"YEMEN HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "yemen_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Yemen') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "yemen_acled['WEEK'] = pd.to_datetime(yemen_acled['WEEK'])\n",
    "\n",
    "yemen_acled['month'] = yemen_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = yemen_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "yemen_hashtag_files = {\n",
    "    '#TalkAboutYemen': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_TurkishWomen.csv',\n",
    "    '#YemenPeace': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_YemenPeace.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtag removed for TalkAboutYemen due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in yemen_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Yemen Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Yemen-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('yemen_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: yemen_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Yemen Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"yemen_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Yemen hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b2305",
   "metadata": {},
   "source": [
    "#### 6) Myanmar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8613cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MYANMAR HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 187 months\n",
      "  Date range: 2009-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 31,662\n",
      "  Total fatalities: 32,707\n",
      "\n",
      "NOTE: Removed hashtag for Posco_StopSupportingSAC due to no data.\n",
      "  ✓ Loaded: #WhatsHappeningInMyanmar  - 70 months, max=100\n",
      "  ✓ Loaded: #MilkTeaAlliance          - 70 months, max=100\n",
      "  ✓ Loaded: #POSCO_StopSupportingSAC  - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 187 months with 3 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "             Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#POSCO_StopSupportingSAC        0.284284            0.044731           69\n",
      "#WhatsHappeningInMyanmar        0.137849            0.162852           69\n",
      "        #MilkTeaAlliance       -0.246314           -0.273124           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#POSCO_StopSupportingSAC:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.291\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.290\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.286\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.284\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.286\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.290\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.291\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#WhatsHappeningInMyanmar:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.111\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.123\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.126\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.138\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.126\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.123\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.111\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#MilkTeaAlliance:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.278\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.266\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.259\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.246\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.259\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.266\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.278\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "May 2021:\n",
      "  ACLED Events: 984\n",
      "  ACLED Fatalities: 548\n",
      "  Search Interest:\n",
      "    - #WhatsHappeningInMyanmar : 0/100\n",
      "    - #MilkTeaAlliance         : 0/100\n",
      "    - #POSCO_StopSupportingSAC : 100/100\n",
      "\n",
      "January 2022:\n",
      "  ACLED Events: 875\n",
      "  ACLED Fatalities: 849\n",
      "  Search Interest:\n",
      "    - #WhatsHappeningInMyanmar : 29/100\n",
      "    - #MilkTeaAlliance         : 0/100\n",
      "    - #POSCO_StopSupportingSAC : 0/100\n",
      "\n",
      "January 2023:\n",
      "  ACLED Events: 846\n",
      "  ACLED Fatalities: 796\n",
      "  Search Interest:\n",
      "    - #WhatsHappeningInMyanmar : 0/100\n",
      "    - #MilkTeaAlliance         : 0/100\n",
      "    - #POSCO_StopSupportingSAC : 0/100\n",
      "\n",
      "October 2021:\n",
      "  ACLED Events: 844\n",
      "  ACLED Fatalities: 832\n",
      "  Search Interest:\n",
      "    - #WhatsHappeningInMyanmar : 0/100\n",
      "    - #MilkTeaAlliance         : 0/100\n",
      "    - #POSCO_StopSupportingSAC : 0/100\n",
      "\n",
      "October 2023:\n",
      "  ACLED Events: 834\n",
      "  ACLED Fatalities: 922\n",
      "  Search Interest:\n",
      "    - #WhatsHappeningInMyanmar : 0/100\n",
      "    - #MilkTeaAlliance         : 0/100\n",
      "    - #POSCO_StopSupportingSAC : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: myanmar_hashtags_acled_vs_trends.html\n",
      "✓ Saved: myanmar_hashtags_#posco_stopsupportingsac_comparison.html\n",
      "✓ Saved: myanmar_hashtags_#whatshappeninginmyanmar_comparison.html\n",
      "✓ Saved: myanmar_hashtags_#milkteaalliance_comparison.html\n",
      "\n",
      "✓ Myanmar hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# MYANMAR HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MYANMAR HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "myanmar_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Myanmar') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "myanmar_acled['WEEK'] = pd.to_datetime(myanmar_acled['WEEK'])\n",
    "\n",
    "myanmar_acled['month'] = myanmar_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = myanmar_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "myanmar_hashtag_files = {\n",
    "    '#WhatsHappeningInMyanmar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_WhatsHappeningInMyanmar.csv',\n",
    "    '#MilkTeaAlliance': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_MilkTeaAlliance.csv',\n",
    "    '#POSCO_StopSupportingSAC': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_POSCOStopSupportingSAC.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Removed hashtag for Posco_StopSupportingSAC due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in myanmar_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Myanmar Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Myanmar-specific hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('myanmar_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: myanmar_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Myanmar Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"myanmar_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Myanmar hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0b29d",
   "metadata": {},
   "source": [
    "#### 7) Afghanistan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3786d6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AFGHANISTAN HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 106 months\n",
      "  Date range: 2016-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 23,895\n",
      "  Total fatalities: 70,176\n",
      "  ✓ Loaded: #Afghanistan              - 70 months, max=100\n",
      "  ✓ Loaded: #Taliban                  - 70 months, max=100.0\n",
      "\n",
      "✓ Merged dataset: 106 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      " Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "    #Taliban       -0.043329           -0.003701           69\n",
      "#Afghanistan       -0.053181            0.013884           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#Taliban:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.042\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.043\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.043\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.043\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.043\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.043\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.042\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#Afghanistan:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.042\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.047\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.049\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.053\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.049\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.047\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.042\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "September 2019:\n",
      "  ACLED Events: 908\n",
      "  ACLED Fatalities: 2,448\n",
      "  Search Interest:\n",
      "\n",
      "August 2019:\n",
      "  ACLED Events: 848\n",
      "  ACLED Fatalities: 3,117\n",
      "  Search Interest:\n",
      "\n",
      "May 2021:\n",
      "  ACLED Events: 816\n",
      "  ACLED Fatalities: 3,335\n",
      "  Search Interest:\n",
      "    - #Afghanistan             : 0/100\n",
      "    - #Taliban                 : 0/100\n",
      "\n",
      "June 2018:\n",
      "  ACLED Events: 736\n",
      "  ACLED Fatalities: 1,778\n",
      "  Search Interest:\n",
      "\n",
      "June 2019:\n",
      "  ACLED Events: 710\n",
      "  ACLED Fatalities: 1,939\n",
      "  Search Interest:\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: afghanistan_hashtags_acled_vs_trends.html\n",
      "✓ Saved: afghanistan_hashtags_#taliban_comparison.html\n",
      "✓ Saved: afghanistan_hashtags_#afghanistan_comparison.html\n",
      "\n",
      "✓ Afghanistan hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# AFGHANISTAN HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AFGHANISTAN HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "afghanistan_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Afghanistan') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "afghanistan_acled['WEEK'] = pd.to_datetime(afghanistan_acled['WEEK'])\n",
    "\n",
    "afghanistan_acled['month'] = afghanistan_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = afghanistan_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "afghanistan_hashtag_files = {\n",
    "    '#Afghanistan': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Afghanistan.csv',\n",
    "    '#Taliban': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Taliban.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in afghanistan_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Afghanistan Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Afghanistan-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('afghanistan_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: afghanistan_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Afghanistan Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"afghanistan_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Afghanistan hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113df33",
   "metadata": {},
   "source": [
    "#### 8) Iraq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e19cafeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IRAQ HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 118 months\n",
      "  Date range: 2015-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 22,556\n",
      "  Total fatalities: 36,368\n",
      "  ✓ Loaded: #Iraq                     - 70 months, max=100\n",
      "  ✓ Loaded: #IraqCeasefire            - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 118 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "   Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "         #Iraq       -0.187089           -0.043383           69\n",
      "#IraqCeasefire             NaN                 NaN           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#Iraq:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.141\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.161\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.174\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.187\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.174\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.161\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.141\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#IraqCeasefire:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +nan\n",
      "  Lag -2 months (searches LEAD  ): correlation = +nan\n",
      "  Lag -1 months (searches LEAD  ): correlation = +nan\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +nan\n",
      "  Lag +1 months (searches LAG   ): correlation = +nan\n",
      "  Lag +2 months (searches LAG   ): correlation = +nan\n",
      "  Lag +3 months (searches LAG   ): correlation = +nan\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "April 2016:\n",
      "  ACLED Events: 540\n",
      "  ACLED Fatalities: 3,261\n",
      "  Search Interest:\n",
      "\n",
      "June 2024:\n",
      "  ACLED Events: 433\n",
      "  ACLED Fatalities: 45\n",
      "  Search Interest:\n",
      "    - #Iraq                    : 0/100\n",
      "    - #IraqCeasefire           : 0/100\n",
      "\n",
      "May 2016:\n",
      "  ACLED Events: 431\n",
      "  ACLED Fatalities: 2,199\n",
      "  Search Interest:\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 430\n",
      "  ACLED Fatalities: 18\n",
      "  Search Interest:\n",
      "    - #Iraq                    : 0/100\n",
      "    - #IraqCeasefire           : 0/100\n",
      "\n",
      "May 2021:\n",
      "  ACLED Events: 416\n",
      "  ACLED Fatalities: 87\n",
      "  Search Interest:\n",
      "    - #Iraq                    : 0/100\n",
      "    - #IraqCeasefire           : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: iraq_hashtags_acled_vs_trends.html\n",
      "✓ Saved: iraq_hashtags_#iraq_comparison.html\n",
      "✓ Saved: iraq_hashtags_#iraqceasefire_comparison.html\n",
      "\n",
      "✓ Iraq hashtags analysis complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kayleeliu/Documents/Code/python/hashtags-for-change/.venv/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IRAQ HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"IRAQ HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "iraq_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Iraq') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "iraq_acled['WEEK'] = pd.to_datetime(iraq_acled['WEEK'])\n",
    "\n",
    "iraq_acled['month'] = iraq_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = iraq_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "iraq_hashtag_files = {\n",
    "    '#Iraq': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Iraq.csv',\n",
    "    '#IraqCeasefire': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_IraqCeasefire.csv'\n",
    "}\n",
    "\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in iraq_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Iraq Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Iraq-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('iraq_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: iraq_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Iraq Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"iraq_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Iraq hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526c8f7",
   "metadata": {},
   "source": [
    "#### 9) Somalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f477db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOMALIA HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 312 months\n",
      "  Date range: 1997-03-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 17,889\n",
      "  Total fatalities: 29,221\n",
      "  ✓ Loaded: #Somaliland               - 70 months, max=100\n",
      "  ✓ Loaded: #SomaliaHumanRights       - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 312 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "        Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#SomaliaHumanRights        0.009107           -0.065277           69\n",
      "        #Somaliland       -0.007841           -0.150355           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#SomaliaHumanRights:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.019\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.016\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.008\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.009\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.008\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.016\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.019\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#Somaliland:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.004\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.001\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.010\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.008\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.010\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.001\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.004\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 288\n",
      "  ACLED Fatalities: 233\n",
      "  Search Interest:\n",
      "    - #Somaliland              : 0/100\n",
      "    - #SomaliaHumanRights      : 0/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 267\n",
      "  ACLED Fatalities: 440\n",
      "  Search Interest:\n",
      "    - #Somaliland              : 0/100\n",
      "    - #SomaliaHumanRights      : 0/100\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 225\n",
      "  ACLED Fatalities: 358\n",
      "  Search Interest:\n",
      "    - #Somaliland              : 0/100\n",
      "    - #SomaliaHumanRights      : 0/100\n",
      "\n",
      "September 2023:\n",
      "  ACLED Events: 183\n",
      "  ACLED Fatalities: 447\n",
      "  Search Interest:\n",
      "    - #Somaliland              : 0/100\n",
      "    - #SomaliaHumanRights      : 0/100\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 181\n",
      "  ACLED Fatalities: 385\n",
      "  Search Interest:\n",
      "    - #Somaliland              : 0/100\n",
      "    - #SomaliaHumanRights      : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: somalia_hashtags_acled_vs_trends.html\n",
      "✓ Saved: somalia_hashtags_#somaliahumanrights_comparison.html\n",
      "✓ Saved: somalia_hashtags_#somaliland_comparison.html\n",
      "\n",
      "✓ Somalia hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# SOMALIA HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SOMALIA HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "somalia_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Somalia') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "somalia_acled['WEEK'] = pd.to_datetime(somalia_acled['WEEK'])\n",
    "\n",
    "somalia_acled['month'] = somalia_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = somalia_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "somalia_hashtag_files = {\n",
    "    '#Somaliland': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Somaliland.csv',\n",
    "    '#SomaliaHumanRights': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_SomaliaHumanRights.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in somalia_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Somalia Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Somalia-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('somalia_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: somalia_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Somalia Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"somalia_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Somalia hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23970d3",
   "metadata": {},
   "source": [
    "#### 10) India/Pakistan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41b21de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INDIA-PAKISTAN HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 190 months\n",
      "  Date range: 2009-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 102,060\n",
      "  Total fatalities: 23,132\n",
      "  ✓ Loaded: #IndiaPakistan            - 70 months, max=100\n",
      "  ✓ Loaded: #LiberateIndia            - 70 months, max=100\n",
      "  ✓ Loaded: #Pakistan                 - 70 months, max=100\n",
      "  ✓ Loaded: #PakistanZindabad         - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 190 months with 4 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "      Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "   #LiberateIndia        0.128510           -0.046084           69\n",
      "#PakistanZindabad        0.109530            0.290239           69\n",
      "   #IndiaPakistan        0.087810            0.355312           69\n",
      "        #Pakistan       -0.125019           -0.148872           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#LiberateIndia:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.129\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.130\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.127\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.129\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.127\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.130\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.129\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#PakistanZindabad:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.109\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.111\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.108\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.110\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.108\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.111\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.109\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#IndiaPakistan:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.085\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.088\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.084\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.088\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.084\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.088\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.085\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 1,804\n",
      "  ACLED Fatalities: 183\n",
      "  Search Interest:\n",
      "    - #IndiaPakistan           : 0/100\n",
      "    - #LiberateIndia           : 0/100\n",
      "    - #Pakistan                : 18/100\n",
      "    - #PakistanZindabad        : 0/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 1,602\n",
      "  ACLED Fatalities: 245\n",
      "  Search Interest:\n",
      "    - #IndiaPakistan           : 0/100\n",
      "    - #LiberateIndia           : 0/100\n",
      "    - #Pakistan                : 22/100\n",
      "    - #PakistanZindabad        : 0/100\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 1,562\n",
      "  ACLED Fatalities: 253\n",
      "  Search Interest:\n",
      "    - #IndiaPakistan           : 0/100\n",
      "    - #LiberateIndia           : 0/100\n",
      "    - #Pakistan                : 16/100\n",
      "    - #PakistanZindabad        : 0/100\n",
      "\n",
      "June 2024:\n",
      "  ACLED Events: 1,548\n",
      "  ACLED Fatalities: 113\n",
      "  Search Interest:\n",
      "    - #IndiaPakistan           : 0/100\n",
      "    - #LiberateIndia           : 0/100\n",
      "    - #Pakistan                : 33/100\n",
      "    - #PakistanZindabad        : 0/100\n",
      "\n",
      "August 2024:\n",
      "  ACLED Events: 1,532\n",
      "  ACLED Fatalities: 183\n",
      "  Search Interest:\n",
      "    - #IndiaPakistan           : 0/100\n",
      "    - #LiberateIndia           : 0/100\n",
      "    - #Pakistan                : 15/100\n",
      "    - #PakistanZindabad        : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: indiaPakistan_hashtags_acled_vs_trends.html\n",
      "✓ Saved: indiaPakistan_hashtags_#liberateindia_comparison.html\n",
      "✓ Saved: indiaPakistan_hashtags_#pakistanzindabad_comparison.html\n",
      "✓ Saved: indiaPakistan_hashtags_#indiapakistan_comparison.html\n",
      "\n",
      "✓ India-Pakistan hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# INDIA-PAKISTAN HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INDIA-PAKISTAN HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "indiaPakistan_acled = acled[\n",
    "    ((acled['COUNTRY'] == 'India') | (acled['COUNTRY'] == 'Pakistan')) & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "indiaPakistan_acled['WEEK'] = pd.to_datetime(indiaPakistan_acled['WEEK'])\n",
    "\n",
    "indiaPakistan_acled['month'] = indiaPakistan_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = indiaPakistan_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "indiaPakistan_hashtag_files = {\n",
    "    '#IndiaPakistan': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_IndiaPakistan.csv',\n",
    "    '#LiberateIndia': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_LiberateIndia.csv',\n",
    "    '#Pakistan': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Pakistan.csv',\n",
    "    '#PakistanZindabad': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_PakistanZindabad.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in indiaPakistan_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'India & Pakistan Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining India & Pakistan-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('indiaPakistan_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: indiaPakistan_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'India-Pakistan Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"indiaPakistan_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ India-Pakistan hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024051d",
   "metadata": {},
   "source": [
    "#### 11) United States [NEED NOTE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19f4abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UNITED STATES HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 70 months\n",
      "  Date range: 2019-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 30,592\n",
      "  Total fatalities: 211\n",
      "\n",
      "NOTE: Hashtag removed for StopGunViolence due to no data.\n",
      "  ✓ Loaded: #StopGunViolence          - 70 months, max=100\n",
      "  ✓ Loaded: #BlackLivesMatter         - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 70 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "      Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#BlackLivesMatter        0.234386            0.115816           69\n",
      " #StopGunViolence       -0.021451            0.373328           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#BlackLivesMatter:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.232\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.234\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.232\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.234\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.232\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.234\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.232\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#StopGunViolence:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.012\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.004\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.005\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.021\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.005\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.004\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.012\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "May 2020:\n",
      "  ACLED Events: 3,886\n",
      "  ACLED Fatalities: 16\n",
      "  Search Interest:\n",
      "    - #StopGunViolence         : 15/100\n",
      "    - #BlackLivesMatter        : 19/100\n",
      "\n",
      "August 2020:\n",
      "  ACLED Events: 1,354\n",
      "  ACLED Fatalities: 6\n",
      "  Search Interest:\n",
      "    - #StopGunViolence         : 11/100\n",
      "    - #BlackLivesMatter        : 14/100\n",
      "\n",
      "October 2020:\n",
      "  ACLED Events: 937\n",
      "  ACLED Fatalities: 1\n",
      "  Search Interest:\n",
      "    - #StopGunViolence         : 11/100\n",
      "    - #BlackLivesMatter        : 5/100\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 824\n",
      "  ACLED Fatalities: 0\n",
      "  Search Interest:\n",
      "    - #StopGunViolence         : 17/100\n",
      "    - #BlackLivesMatter        : 2/100\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 753\n",
      "  ACLED Fatalities: 3\n",
      "  Search Interest:\n",
      "    - #StopGunViolence         : 18/100\n",
      "    - #BlackLivesMatter        : 2/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: us_hashtags_acled_vs_trends.html\n",
      "✓ Saved: us_hashtags_#blacklivesmatter_comparison.html\n",
      "✓ Saved: us_hashtags_#stopgunviolence_comparison.html\n",
      "\n",
      "✓ United States hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# UNITED STATES HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UNITED STATES HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "us_acled = acled[\n",
    "    (acled['COUNTRY'] == 'United States') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "us_acled['WEEK'] = pd.to_datetime(us_acled['WEEK'])\n",
    "\n",
    "us_acled['month'] = us_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = us_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "us_hashtag_files = {\n",
    "    '#StopGunViolence': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StopGunViolence.csv',\n",
    "    '#BlackLivesMatter': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_BlackLivesMatter.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtag removed for StopGunViolence due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in us_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'United States Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining United States-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('us_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: us_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'United States Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"us_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ United States hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b2df8",
   "metadata": {},
   "source": [
    "#### 12) Mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31b1bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MEXICO HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 94 months\n",
      "  Date range: 2017-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 37,588\n",
      "  Total fatalities: 22,233\n",
      "  ✓ Loaded: #StandWithMexico          - 70 months, max=100\n",
      "  ✓ Loaded: #HopeForMexico            - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 94 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "     Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#StandWithMexico        0.146900            0.212126           69\n",
      "  #HopeForMexico        0.046268           -0.091090           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#StandWithMexico:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.153\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.154\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.145\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.147\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.145\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.154\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.153\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#HopeForMexico:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.049\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.050\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.045\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.046\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.045\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.050\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.049\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 754\n",
      "  ACLED Fatalities: 339\n",
      "  Search Interest:\n",
      "    - #StandWithMexico         : 0/100\n",
      "    - #HopeForMexico           : 0/100\n",
      "\n",
      "August 2024:\n",
      "  ACLED Events: 713\n",
      "  ACLED Fatalities: 285\n",
      "  Search Interest:\n",
      "    - #StandWithMexico         : 0/100\n",
      "    - #HopeForMexico           : 0/100\n",
      "\n",
      "September 2018:\n",
      "  ACLED Events: 683\n",
      "  ACLED Fatalities: 472\n",
      "  Search Interest:\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 671\n",
      "  ACLED Fatalities: 365\n",
      "  Search Interest:\n",
      "    - #StandWithMexico         : 0/100\n",
      "    - #HopeForMexico           : 0/100\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 663\n",
      "  ACLED Fatalities: 371\n",
      "  Search Interest:\n",
      "    - #StandWithMexico         : 0/100\n",
      "    - #HopeForMexico           : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: mexico_hashtags_acled_vs_trends.html\n",
      "✓ Saved: mexico_hashtags_#standwithmexico_comparison.html\n",
      "✓ Saved: mexico_hashtags_#hopeformexico_comparison.html\n",
      "\n",
      "✓ Mexico hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# MEXICO HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MEXICO HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "mexico_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Mexico') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "mexico_acled['WEEK'] = pd.to_datetime(mexico_acled['WEEK'])\n",
    "\n",
    "mexico_acled['month'] = mexico_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = mexico_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "mexico_hashtag_files = {\n",
    "    '#StandWithMexico': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StandWithMexico.csv',\n",
    "    '#HopeForMexico': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_HopeForMexico.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in mexico_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Mexico Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Mexico-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('mexico_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: mexico_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Mexico Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"mexico_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Mexico hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e52e5",
   "metadata": {},
   "source": [
    "#### 13) Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c34c1e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BRAZIL HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 94 months\n",
      "  Date range: 2017-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 35,287\n",
      "  Total fatalities: 18,930\n",
      "  ✓ Loaded: #SaveBrazil               - 70 months, max=100\n",
      "  ✓ Loaded: #RioCrisis                - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 94 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      " #RioCrisis        0.009725           -0.024521           69\n",
      "#SaveBrazil       -0.044267           -0.072561           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#RioCrisis:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.009\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.009\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.008\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.010\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.008\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.009\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.009\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#SaveBrazil:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.045\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.045\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.046\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.044\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.046\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.045\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.045\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "October 2022:\n",
      "  ACLED Events: 1,867\n",
      "  ACLED Fatalities: 286\n",
      "  Search Interest:\n",
      "    - #SaveBrazil              : 0/100\n",
      "    - #RioCrisis               : 0/100\n",
      "\n",
      "May 2018:\n",
      "  ACLED Events: 1,140\n",
      "  ACLED Fatalities: 103\n",
      "  Search Interest:\n",
      "\n",
      "March 2018:\n",
      "  ACLED Events: 868\n",
      "  ACLED Fatalities: 341\n",
      "  Search Interest:\n",
      "\n",
      "July 2018:\n",
      "  ACLED Events: 650\n",
      "  ACLED Fatalities: 349\n",
      "  Search Interest:\n",
      "\n",
      "September 2018:\n",
      "  ACLED Events: 630\n",
      "  ACLED Fatalities: 227\n",
      "  Search Interest:\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: brazil_hashtags_acled_vs_trends.html\n",
      "✓ Saved: brazil_hashtags_#riocrisis_comparison.html\n",
      "✓ Saved: brazil_hashtags_#savebrazil_comparison.html\n",
      "\n",
      "✓ Brazil hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# BRAZIL HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BRAZIL HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "brazil_acled = acled[\n",
    "    (acled['COUNTRY'] == 'Brazil') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "brazil_acled['WEEK'] = pd.to_datetime(brazil_acled['WEEK'])\n",
    "\n",
    "brazil_acled['month'] = brazil_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = brazil_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "brazil_hashtag_files = {\n",
    "    '#SaveBrazil': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_SaveBrazil.csv',\n",
    "    '#RioCrisis': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_RioCrisis.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in brazil_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Brazil Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Brazil-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('brazil_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: brazil_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Brazil Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"brazil_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Brazil hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5abf3a",
   "metadata": {},
   "source": [
    "### II. Thematic Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d27558",
   "metadata": {},
   "source": [
    "#### 1) Human Rights & Protests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2841c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HUMAN RIGHTS & PROTESTS HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 347 months\n",
      "  Date range: 1996-12-01 00:00:00 to 2025-10-01 00:00:00\n",
      "  Total events: 2,772,023\n",
      "  Total fatalities: 2,399,712\n",
      "\n",
      "NOTE: Hashtags removed for FreePress and PeopleNotProfit due to no data.\n",
      "  ✓ Loaded: #NeverAgain               - 70 months, max=100\n",
      "  ✓ Loaded: #Democracy                - 70 months, max=100\n",
      "  ✓ Loaded: #FreeSpeech               - 70 months, max=100\n",
      "  ✓ Loaded: #HumanRights              - 70 months, max=100\n",
      "  ✓ Loaded: #FreePress                - 70 months, max=100\n",
      "  ✓ Loaded: #YouthForDemocracy        - 70 months, max=100\n",
      "  ✓ Loaded: #Protest                  - 70 months, max=100\n",
      "  ✓ Loaded: #DemocracyForAll          - 70 months, max=100\n",
      "  ✓ Loaded: #NeverForget              - 70 months, max=100\n",
      "  ✓ Loaded: #Equality                 - 70 months, max=100\n",
      "  ✓ Loaded: #Justice                  - 70 months, max=100\n",
      "  ✓ Loaded: #Freedom                  - 70 months, max=100\n",
      "  ✓ Loaded: #Change                   - 70 months, max=100\n",
      "  ✓ Loaded: #FridaysForFuture         - 70 months, max=100\n",
      "  ✓ Loaded: #PeopleNotProfit          - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 347 months with 15 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "       Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "  #PeopleNotProfit        0.545740            0.442576           70\n",
      "#YouthForDemocracy        0.283151            0.295459           70\n",
      "  #DemocracyForAll        0.175124            0.105230           70\n",
      "        #Democracy        0.156256            0.263563           70\n",
      "      #HumanRights       -0.000169           -0.058766           70\n",
      "           #Change       -0.024438            0.014212           70\n",
      "       #FreeSpeech       -0.031586           -0.073955           70\n",
      "         #Equality       -0.065250           -0.133939           70\n",
      "       #NeverAgain       -0.073931           -0.133943           70\n",
      "          #Protest       -0.079658           -0.143917           70\n",
      "          #Freedom       -0.095399           -0.233789           70\n",
      "        #FreePress       -0.104105           -0.222538           70\n",
      "          #Justice       -0.147058           -0.259753           70\n",
      "      #NeverForget       -0.254770           -0.364210           70\n",
      " #FridaysForFuture       -0.298057           -0.246360           70\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#PeopleNotProfit:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.565\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.589\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.588\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.546\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.588\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.589\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.565\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#YouthForDemocracy:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.307\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.288\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.285\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.283\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.285\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.288\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.307\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#DemocracyForAll:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.138\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.130\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.173\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.175\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.173\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.130\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.138\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#Democracy:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.167\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.157\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.155\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.156\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.155\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.157\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.167\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#HumanRights:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.005\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.007\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.006\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.000\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.006\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.007\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.005\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 40,750\n",
      "  ACLED Fatalities: 27,287\n",
      "  Search Interest:\n",
      "    - #NeverAgain              : 0/100\n",
      "    - #Democracy               : 0/100\n",
      "    - #FreeSpeech              : 0/100\n",
      "    - #HumanRights             : 0/100\n",
      "    - #FreePress               : 30/100\n",
      "    - #YouthForDemocracy       : 100/100\n",
      "    - #Protest                 : 0/100\n",
      "    - #DemocracyForAll         : 0/100\n",
      "    - #NeverForget             : 0/100\n",
      "    - #Equality                : 0/100\n",
      "    - #Justice                 : 25/100\n",
      "    - #Freedom                 : 0/100\n",
      "    - #Change                  : 0/100\n",
      "    - #FridaysForFuture        : 0/100\n",
      "    - #PeopleNotProfit         : 75/100\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 40,268\n",
      "  ACLED Fatalities: 28,054\n",
      "  Search Interest:\n",
      "    - #NeverAgain              : 0/100\n",
      "    - #Democracy               : 0/100\n",
      "    - #FreeSpeech              : 0/100\n",
      "    - #HumanRights             : 0/100\n",
      "    - #FreePress               : 30/100\n",
      "    - #YouthForDemocracy       : 0/100\n",
      "    - #Protest                 : 0/100\n",
      "    - #DemocracyForAll         : 0/100\n",
      "    - #NeverForget             : 0/100\n",
      "    - #Equality                : 0/100\n",
      "    - #Justice                 : 10/100\n",
      "    - #Freedom                 : 0/100\n",
      "    - #Change                  : 0/100\n",
      "    - #FridaysForFuture        : 66/100\n",
      "    - #PeopleNotProfit         : 73/100\n",
      "\n",
      "August 2024:\n",
      "  ACLED Events: 38,045\n",
      "  ACLED Fatalities: 22,460\n",
      "  Search Interest:\n",
      "    - #NeverAgain              : 0/100\n",
      "    - #Democracy               : 0/100\n",
      "    - #FreeSpeech              : 0/100\n",
      "    - #HumanRights             : 0/100\n",
      "    - #FreePress               : 27/100\n",
      "    - #YouthForDemocracy       : 0/100\n",
      "    - #Protest                 : 0/100\n",
      "    - #DemocracyForAll         : 0/100\n",
      "    - #NeverForget             : 0/100\n",
      "    - #Equality                : 0/100\n",
      "    - #Justice                 : 18/100\n",
      "    - #Freedom                 : 50/100\n",
      "    - #Change                  : 0/100\n",
      "    - #FridaysForFuture        : 0/100\n",
      "    - #PeopleNotProfit         : 40/100\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 37,892\n",
      "  ACLED Fatalities: 23,132\n",
      "  Search Interest:\n",
      "    - #NeverAgain              : 10/100\n",
      "    - #Democracy               : 0/100\n",
      "    - #FreeSpeech              : 0/100\n",
      "    - #HumanRights             : 0/100\n",
      "    - #FreePress               : 27/100\n",
      "    - #YouthForDemocracy       : 0/100\n",
      "    - #Protest                 : 0/100\n",
      "    - #DemocracyForAll         : 0/100\n",
      "    - #NeverForget             : 0/100\n",
      "    - #Equality                : 0/100\n",
      "    - #Justice                 : 9/100\n",
      "    - #Freedom                 : 0/100\n",
      "    - #Change                  : 0/100\n",
      "    - #FridaysForFuture        : 0/100\n",
      "    - #PeopleNotProfit         : 58/100\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 37,324\n",
      "  ACLED Fatalities: 19,951\n",
      "  Search Interest:\n",
      "    - #NeverAgain              : 0/100\n",
      "    - #Democracy               : 0/100\n",
      "    - #FreeSpeech              : 0/100\n",
      "    - #HumanRights             : 0/100\n",
      "    - #FreePress               : 90/100\n",
      "    - #YouthForDemocracy       : 0/100\n",
      "    - #Protest                 : 0/100\n",
      "    - #DemocracyForAll         : 0/100\n",
      "    - #NeverForget             : 16/100\n",
      "    - #Equality                : 0/100\n",
      "    - #Justice                 : 24/100\n",
      "    - #Freedom                 : 47/100\n",
      "    - #Change                  : 0/100\n",
      "    - #FridaysForFuture        : 0/100\n",
      "    - #PeopleNotProfit         : 56/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: humanRights_hashtags_acled_vs_trends.html\n",
      "✓ Saved: humanRights_hashtags_#peoplenotprofit_comparison.html\n",
      "✓ Saved: humanRights_hashtags_#youthfordemocracy_comparison.html\n",
      "✓ Saved: humanRights_hashtags_#democracyforall_comparison.html\n",
      "✓ Saved: humanRights_hashtags_#democracy_comparison.html\n",
      "✓ Saved: humanRights_hashtags_#humanrights_comparison.html\n",
      "\n",
      "✓ Human Rights & Protests hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# HUMAN RIGHTS & PROTESTS HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HUMAN RIGHTS & PROTESTS HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "acled_copy = acled.copy()\n",
    "\n",
    "acled_copy['WEEK'] = pd.to_datetime(acled_copy['WEEK'])\n",
    "\n",
    "acled_copy['month'] = acled_copy['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = acled_copy.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "human_rights_hashtag_files = {\n",
    "    '#NeverAgain': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_NeverAgain.csv',\n",
    "    '#Democracy': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Democracy.csv',\n",
    "    '#FreeSpeech': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FreeSpeech.csv',\n",
    "    '#HumanRights': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_HumanRights.csv',\n",
    "    '#FreePress': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FreePress.csv',\n",
    "    '#YouthForDemocracy': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_YouthForDemocracy.csv',\n",
    "    '#Protest': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Protest.csv',\n",
    "    '#DemocracyForAll': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_DemocracyForAll.csv',\n",
    "    '#NeverForget': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_NeverForget.csv',\n",
    "    '#Equality': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Equality.csv',\n",
    "    '#Justice': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Justice.csv',\n",
    "    '#Freedom': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Freedom.csv',\n",
    "    '#Change': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Change.csv',\n",
    "    '#FridaysForFuture': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FridaysForFuture.csv',\n",
    "    '#PeopleNotProfit': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_PeopleNotProfit.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtags removed for FreePress and PeopleNotProfit due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in human_rights_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(5)['Search Term'].tolist() # changed to top 5\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Human Rights & Protests Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Human Rights & Protests-related Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('humanRights_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: humanRights_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Human Rights & Protests Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"humanRights_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Human Rights & Protests hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b78f64",
   "metadata": {},
   "source": [
    "#### 2) Gender & Social Justice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38d85716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENDER & SOCIAL JUSTICE HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 347 months\n",
      "  Date range: 1996-12-01 00:00:00 to 2025-10-01 00:00:00\n",
      "  Total events: 2,772,023\n",
      "  Total fatalities: 2,399,712\n",
      "\n",
      "NOTE: Hashtags removed & spaces added for StopFundingHate, GenerationEquality, and TransRightsAreHumanRights due to no data.\n",
      "  ✓ Loaded: #MeToo                    - 70 months, max=100\n",
      "  ✓ Loaded: #StopFundingHate          - 70 months, max=100\n",
      "  ✓ Loaded: #WomensMarch              - 70 months, max=100\n",
      "  ✓ Loaded: #TimesUp                  - 70 months, max=100\n",
      "  ✓ Loaded: #GenerationEquality       - 70 months, max=100\n",
      "  ✓ Loaded: #MyBodyMyChoice           - 70 months, max=100\n",
      "  ✓ Loaded: #ProChoice                - 70 months, max=100\n",
      "  ✓ Loaded: #LoveIsLove               - 70 months, max=100\n",
      "  ✓ Loaded: #TransRights              - 70 months, max=100\n",
      "  ✓ Loaded: #EqualityForAll           - 70 months, max=100\n",
      "  ✓ Loaded: #TransRightsAreHumanRights - 70 months, max=100\n",
      "  ✓ Loaded: #EndSexualViolence        - 70 months, max=100\n",
      "  ✓ Loaded: #WomensRights             - 70 months, max=100\n",
      "  ✓ Loaded: #LGBTQ+                   - 70 months, max=100\n",
      "  ✓ Loaded: #GayPride                 - 70 months, max=100\n",
      "  ✓ Loaded: #ImmigrantRights          - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 347 months with 16 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "               Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "              #WomensMarch        0.156256            0.263563           70\n",
      "                 #GayPride        0.145684            0.158075           70\n",
      "#TransRightsAreHumanRights        0.120556           -0.007971           70\n",
      "        #EndSexualViolence        0.110399            0.258500           70\n",
      "             #WomensRights        0.083334            0.032500           70\n",
      "                    #MeToo        0.019839           -0.068243           70\n",
      "                #ProChoice       -0.013296           -0.046301           70\n",
      "          #ImmigrantRights       -0.016102           -0.109799           70\n",
      "           #EqualityForAll       -0.028823           -0.066033           70\n",
      "              #TransRights       -0.036213            0.154518           70\n",
      "           #MyBodyMyChoice       -0.053539           -0.110876           70\n",
      "          #StopFundingHate       -0.136041           -0.034610           70\n",
      "               #LoveIsLove       -0.138189           -0.267895           70\n",
      "                   #LGBTQ+       -0.218435           -0.205330           70\n",
      "       #GenerationEquality       -0.225480           -0.188745           70\n",
      "                  #TimesUp       -0.324076           -0.308707           70\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#WomensMarch:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.167\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.157\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.155\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.156\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.155\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.157\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.167\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#GayPride:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.151\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.144\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.141\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.146\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.141\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.144\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.151\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#TransRightsAreHumanRights:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.089\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.081\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.110\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.121\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.110\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.081\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.089\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#EndSexualViolence:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.115\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.109\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.107\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.110\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.107\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.109\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.115\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#WomensRights:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.087\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.082\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.081\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.083\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.081\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.082\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.087\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 40,750\n",
      "  ACLED Fatalities: 27,287\n",
      "  Search Interest:\n",
      "    - #MeToo                   : 46/100\n",
      "    - #StopFundingHate         : 5/100\n",
      "    - #WomensMarch             : 0/100\n",
      "    - #TimesUp                 : 0/100\n",
      "    - #GenerationEquality      : 18/100\n",
      "    - #MyBodyMyChoice          : 0/100\n",
      "    - #ProChoice               : 0/100\n",
      "    - #LoveIsLove              : 8/100\n",
      "    - #TransRights             : 0/100\n",
      "    - #EqualityForAll          : 0/100\n",
      "    - #TransRightsAreHumanRights: 67/100\n",
      "    - #EndSexualViolence       : 0/100\n",
      "    - #WomensRights            : 0/100\n",
      "    - #LGBTQ+                  : 0/100\n",
      "    - #GayPride                : 100/100\n",
      "    - #ImmigrantRights         : 0/100\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 40,268\n",
      "  ACLED Fatalities: 28,054\n",
      "  Search Interest:\n",
      "    - #MeToo                   : 59/100\n",
      "    - #StopFundingHate         : 0/100\n",
      "    - #WomensMarch             : 0/100\n",
      "    - #TimesUp                 : 0/100\n",
      "    - #GenerationEquality      : 20/100\n",
      "    - #MyBodyMyChoice          : 0/100\n",
      "    - #ProChoice               : 0/100\n",
      "    - #LoveIsLove              : 8/100\n",
      "    - #TransRights             : 0/100\n",
      "    - #EqualityForAll          : 0/100\n",
      "    - #TransRightsAreHumanRights: 49/100\n",
      "    - #EndSexualViolence       : 0/100\n",
      "    - #WomensRights            : 0/100\n",
      "    - #LGBTQ+                  : 0/100\n",
      "    - #GayPride                : 0/100\n",
      "    - #ImmigrantRights         : 0/100\n",
      "\n",
      "August 2024:\n",
      "  ACLED Events: 38,045\n",
      "  ACLED Fatalities: 22,460\n",
      "  Search Interest:\n",
      "    - #MeToo                   : 64/100\n",
      "    - #StopFundingHate         : 0/100\n",
      "    - #WomensMarch             : 0/100\n",
      "    - #TimesUp                 : 0/100\n",
      "    - #GenerationEquality      : 12/100\n",
      "    - #MyBodyMyChoice          : 0/100\n",
      "    - #ProChoice               : 0/100\n",
      "    - #LoveIsLove              : 12/100\n",
      "    - #TransRights             : 0/100\n",
      "    - #EqualityForAll          : 0/100\n",
      "    - #TransRightsAreHumanRights: 12/100\n",
      "    - #EndSexualViolence       : 0/100\n",
      "    - #WomensRights            : 0/100\n",
      "    - #LGBTQ+                  : 0/100\n",
      "    - #GayPride                : 0/100\n",
      "    - #ImmigrantRights         : 0/100\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 37,892\n",
      "  ACLED Fatalities: 23,132\n",
      "  Search Interest:\n",
      "    - #MeToo                   : 49/100\n",
      "    - #StopFundingHate         : 0/100\n",
      "    - #WomensMarch             : 0/100\n",
      "    - #TimesUp                 : 31/100\n",
      "    - #GenerationEquality      : 14/100\n",
      "    - #MyBodyMyChoice          : 0/100\n",
      "    - #ProChoice               : 0/100\n",
      "    - #LoveIsLove              : 0/100\n",
      "    - #TransRights             : 0/100\n",
      "    - #EqualityForAll          : 0/100\n",
      "    - #TransRightsAreHumanRights: 46/100\n",
      "    - #EndSexualViolence       : 0/100\n",
      "    - #WomensRights            : 0/100\n",
      "    - #LGBTQ+                  : 40/100\n",
      "    - #GayPride                : 0/100\n",
      "    - #ImmigrantRights         : 0/100\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 37,324\n",
      "  ACLED Fatalities: 19,951\n",
      "  Search Interest:\n",
      "    - #MeToo                   : 49/100\n",
      "    - #StopFundingHate         : 6/100\n",
      "    - #WomensMarch             : 0/100\n",
      "    - #TimesUp                 : 0/100\n",
      "    - #GenerationEquality      : 49/100\n",
      "    - #MyBodyMyChoice          : 0/100\n",
      "    - #ProChoice               : 0/100\n",
      "    - #LoveIsLove              : 7/100\n",
      "    - #TransRights             : 0/100\n",
      "    - #EqualityForAll          : 0/100\n",
      "    - #TransRightsAreHumanRights: 29/100\n",
      "    - #EndSexualViolence       : 0/100\n",
      "    - #WomensRights            : 0/100\n",
      "    - #LGBTQ+                  : 0/100\n",
      "    - #GayPride                : 0/100\n",
      "    - #ImmigrantRights         : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: genderSocialJustice_hashtags_acled_vs_trends.html\n",
      "✓ Saved: genderSocialJustice_hashtags_#womensmarch_comparison.html\n",
      "✓ Saved: genderSocialJustice_hashtags_#gaypride_comparison.html\n",
      "✓ Saved: genderSocialJustice_hashtags_#transrightsarehumanrights_comparison.html\n",
      "✓ Saved: genderSocialJustice_hashtags_#endsexualviolence_comparison.html\n",
      "✓ Saved: genderSocialJustice_hashtags_#womensrights_comparison.html\n",
      "\n",
      "✓ Gender & Social Justice hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# GENDER & SOCIAL JUSTICE HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GENDER & SOCIAL JUSTICE HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "acled_copy = acled.copy()\n",
    "\n",
    "acled_copy['WEEK'] = pd.to_datetime(acled_copy['WEEK'])\n",
    "\n",
    "acled_copy['month'] = acled_copy['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = acled_copy.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "genderSocialJustice_hashtag_files = {\n",
    "    '#MeToo': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_MeToo.csv',\n",
    "    '#StopFundingHate': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StopFundingHate.csv',\n",
    "    '#WomensMarch': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_WomensMarch.csv',\n",
    "    '#TimesUp': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_TimesUp.csv',\n",
    "    '#GenerationEquality': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_GenerationEquality.csv',\n",
    "    '#MyBodyMyChoice': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_MyBodyMyChoice.csv',\n",
    "    '#ProChoice': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_ProChoice.csv',\n",
    "    '#LoveIsLove': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_LoveIsLove.csv',\n",
    "    '#TransRights': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_TransRights.csv',\n",
    "    '#EqualityForAll': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_EqualityForAll.csv',\n",
    "    '#TransRightsAreHumanRights': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_TransRightsAreHumanRights.csv',\n",
    "    '#EndSexualViolence': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_EndSexualViolence.csv',\n",
    "    '#WomensRights': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_WomensRights.csv',\n",
    "    '#LGBTQ+': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_LGBTQ+.csv',\n",
    "    '#GayPride': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_GayPride.csv',\n",
    "    '#ImmigrantRights': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_ImmigrantRights.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtags removed & spaces added for StopFundingHate, GenerationEquality, and TransRightsAreHumanRights due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in genderSocialJustice_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(5)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Gender & Social Justice Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Gener & Social Justice-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('genderSocialJustice_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: genderSocialJustice_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Gender & Social Justice Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"genderSocialJustice_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Gender & Social Justice hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec758a5",
   "metadata": {},
   "source": [
    "#### 3) Conflict & Peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96435b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONFLICT & PEACE HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 347 months\n",
      "  Date range: 1996-12-01 00:00:00 to 2025-10-01 00:00:00\n",
      "  Total events: 2,772,023\n",
      "  Total fatalities: 2,399,712\n",
      "\n",
      "NOTE: Hashtags removed & spaces added for RefugeeRelief, PeaceForAll, and StandWithPeace due to no data.\n",
      "  ✓ Loaded: #NoWarCrimes              - 70 months, max=100\n",
      "  ✓ Loaded: #Peace                    - 70 months, max=100\n",
      "  ✓ Loaded: #NoWar                    - 70 months, max=100\n",
      "  ✓ Loaded: #StopWar                  - 70 months, max=100\n",
      "  ✓ Loaded: #StopTheWar               - 70 months, max=100\n",
      "  ✓ Loaded: #HumanatarianCrisis       - 70 months, max=100\n",
      "  ✓ Loaded: #RefugeeRelief            - 70 months, max=100\n",
      "  ✓ Loaded: #PeaceForAll              - 70 months, max=100\n",
      "  ✓ Loaded: #Solidarity               - 70 months, max=100\n",
      "  ✓ Loaded: #Ceasefire                - 70 months, max=100\n",
      "  ✓ Loaded: #CeasefireNOW             - 70 months, max=100\n",
      "  ✓ Loaded: #StopGenocide             - 70 months, max=100\n",
      "  ✓ Loaded: #Aid                      - 70 months, max=100\n",
      "  ✓ Loaded: #StandWithPeace           - 70 months, max=100\n",
      "  ✓ Loaded: #SaveHumanity             - 70 months, max=100\n",
      "  ✓ Loaded: #EndViolence              - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 347 months with 16 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "        Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "       #PeaceForAll        0.542336            0.437301           70\n",
      "    #StandWithPeace        0.521904            0.437675           70\n",
      "      #SaveHumanity        0.195844            0.198120           70\n",
      "      #CeasefireNOW        0.181253            0.338215           70\n",
      "         #Ceasefire        0.175371            0.233197           70\n",
      "     #RefugeeRelief        0.164831            0.051669           70\n",
      "       #NoWarCrimes        0.054078            0.057088           70\n",
      "#HumanatarianCrisis        0.048551            0.117213           70\n",
      "      #StopGenocide        0.025925            0.083149           70\n",
      "               #Aid       -0.055359           -0.051803           70\n",
      "       #EndViolence       -0.064264           -0.091544           70\n",
      "           #StopWar       -0.076465           -0.072157           70\n",
      "        #StopTheWar       -0.078155           -0.061208           70\n",
      "             #NoWar       -0.089247           -0.105211           70\n",
      "             #Peace       -0.170997           -0.309847           70\n",
      "        #Solidarity       -0.281472           -0.174437           70\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#PeaceForAll:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.586\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.614\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.616\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.542\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.616\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.614\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.586\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#StandWithPeace:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.587\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.621\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.611\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.522\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.611\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.621\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.587\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#SaveHumanity:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.167\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.157\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.194\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.196\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.194\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.157\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.167\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#CeasefireNOW:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.189\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.179\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.176\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.181\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.176\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.179\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.189\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#Ceasefire:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.247\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.174\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.170\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.175\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.170\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.174\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.247\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 40,750\n",
      "  ACLED Fatalities: 27,287\n",
      "  Search Interest:\n",
      "    - #NoWarCrimes             : 0/100\n",
      "    - #Peace                   : 0/100\n",
      "    - #NoWar                   : 0/100\n",
      "    - #StopWar                 : 0/100\n",
      "    - #StopTheWar              : 0/100\n",
      "    - #HumanatarianCrisis      : 0/100\n",
      "    - #RefugeeRelief           : 34/100\n",
      "    - #PeaceForAll             : 76/100\n",
      "    - #Solidarity              : 0/100\n",
      "    - #Ceasefire               : 0/100\n",
      "    - #CeasefireNOW            : 0/100\n",
      "    - #StopGenocide            : 0/100\n",
      "    - #Aid                     : 0/100\n",
      "    - #StandWithPeace          : 79/100\n",
      "    - #SaveHumanity            : 0/100\n",
      "    - #EndViolence             : 0/100\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 40,268\n",
      "  ACLED Fatalities: 28,054\n",
      "  Search Interest:\n",
      "    - #NoWarCrimes             : 0/100\n",
      "    - #Peace                   : 0/100\n",
      "    - #NoWar                   : 0/100\n",
      "    - #StopWar                 : 0/100\n",
      "    - #StopTheWar              : 0/100\n",
      "    - #HumanatarianCrisis      : 0/100\n",
      "    - #RefugeeRelief           : 39/100\n",
      "    - #PeaceForAll             : 68/100\n",
      "    - #Solidarity              : 0/100\n",
      "    - #Ceasefire               : 0/100\n",
      "    - #CeasefireNOW            : 0/100\n",
      "    - #StopGenocide            : 0/100\n",
      "    - #Aid                     : 0/100\n",
      "    - #StandWithPeace          : 61/100\n",
      "    - #SaveHumanity            : 0/100\n",
      "    - #EndViolence             : 0/100\n",
      "\n",
      "August 2024:\n",
      "  ACLED Events: 38,045\n",
      "  ACLED Fatalities: 22,460\n",
      "  Search Interest:\n",
      "    - #NoWarCrimes             : 0/100\n",
      "    - #Peace                   : 0/100\n",
      "    - #NoWar                   : 0/100\n",
      "    - #StopWar                 : 0/100\n",
      "    - #StopTheWar              : 0/100\n",
      "    - #HumanatarianCrisis      : 0/100\n",
      "    - #RefugeeRelief           : 31/100\n",
      "    - #PeaceForAll             : 45/100\n",
      "    - #Solidarity              : 0/100\n",
      "    - #Ceasefire               : 0/100\n",
      "    - #CeasefireNOW            : 0/100\n",
      "    - #StopGenocide            : 39/100\n",
      "    - #Aid                     : 0/100\n",
      "    - #StandWithPeace          : 36/100\n",
      "    - #SaveHumanity            : 0/100\n",
      "    - #EndViolence             : 0/100\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 37,892\n",
      "  ACLED Fatalities: 23,132\n",
      "  Search Interest:\n",
      "    - #NoWarCrimes             : 0/100\n",
      "    - #Peace                   : 0/100\n",
      "    - #NoWar                   : 0/100\n",
      "    - #StopWar                 : 0/100\n",
      "    - #StopTheWar              : 0/100\n",
      "    - #HumanatarianCrisis      : 0/100\n",
      "    - #RefugeeRelief           : 37/100\n",
      "    - #PeaceForAll             : 67/100\n",
      "    - #Solidarity              : 0/100\n",
      "    - #Ceasefire               : 100/100\n",
      "    - #CeasefireNOW            : 0/100\n",
      "    - #StopGenocide            : 0/100\n",
      "    - #Aid                     : 0/100\n",
      "    - #StandWithPeace          : 59/100\n",
      "    - #SaveHumanity            : 0/100\n",
      "    - #EndViolence             : 0/100\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 37,324\n",
      "  ACLED Fatalities: 19,951\n",
      "  Search Interest:\n",
      "    - #NoWarCrimes             : 0/100\n",
      "    - #Peace                   : 36/100\n",
      "    - #NoWar                   : 0/100\n",
      "    - #StopWar                 : 0/100\n",
      "    - #StopTheWar              : 0/100\n",
      "    - #HumanatarianCrisis      : 0/100\n",
      "    - #RefugeeRelief           : 73/100\n",
      "    - #PeaceForAll             : 68/100\n",
      "    - #Solidarity              : 0/100\n",
      "    - #Ceasefire               : 0/100\n",
      "    - #CeasefireNOW            : 0/100\n",
      "    - #StopGenocide            : 0/100\n",
      "    - #Aid                     : 0/100\n",
      "    - #StandWithPeace          : 74/100\n",
      "    - #SaveHumanity            : 0/100\n",
      "    - #EndViolence             : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: conflictPeace_hashtags_acled_vs_trends.html\n",
      "✓ Saved: conflictPeace_hashtags_#peaceforall_comparison.html\n",
      "✓ Saved: conflictPeace_hashtags_#standwithpeace_comparison.html\n",
      "✓ Saved: conflictPeace_hashtags_#savehumanity_comparison.html\n",
      "✓ Saved: conflictPeace_hashtags_#ceasefirenow_comparison.html\n",
      "✓ Saved: conflictPeace_hashtags_#ceasefire_comparison.html\n",
      "\n",
      "✓ Conflict & Peace hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# COFLICT & PEACE HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONFLICT & PEACE HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "acled_copy = acled.copy()\n",
    "\n",
    "acled_copy['WEEK'] = pd.to_datetime(acled_copy['WEEK'])\n",
    "\n",
    "acled_copy['month'] = acled_copy['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = acled_copy.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "conflictPeace_hashtag_files = {\n",
    "    '#NoWarCrimes': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_NoWarCrimes.csv',\n",
    "    '#Peace': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Peace.csv',\n",
    "    '#NoWar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_NoWar.csv',\n",
    "    '#StopWar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StopWar.csv',\n",
    "    '#StopTheWar': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StopTheWar.csv',\n",
    "    '#HumanatarianCrisis': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_HumanatarianCrisis.csv',\n",
    "    '#RefugeeRelief': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_RefugeeRelief.csv',\n",
    "    '#PeaceForAll': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_PeaceForAll.csv',\n",
    "    '#Solidarity': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Solidarity.csv',\n",
    "    '#Ceasefire': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Ceasefire.csv',\n",
    "    '#CeasefireNOW': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_CeasefireNOW.csv',\n",
    "    '#StopGenocide': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StopGenocide.csv',\n",
    "    '#Aid': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_Aid.csv',\n",
    "    '#StandWithPeace': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_StandWithPeace.csv',\n",
    "    '#SaveHumanity': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_SaveHumanity.csv',\n",
    "    '#EndViolence': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_EndViolence.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtags removed & spaces added for RefugeeRelief, PeaceForAll, and StandWithPeace due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in conflictPeace_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(5)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Conflict & Peace Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Conflict & Peace-specific Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('conflictPeace_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: conflictPeace_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Conflict & Peace Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"conflictPeace_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Conflict & Peace hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf6cedc",
   "metadata": {},
   "source": [
    "### III. Regional Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa95514",
   "metadata": {},
   "source": [
    "#### 1) Middle East"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07572058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MIDDLE EAST HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 130 months\n",
      "  Date range: 2014-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 189,134\n",
      "  Total fatalities: 171,435\n",
      "\n",
      "NOTE: Hashtag removed for MENA due to no data.\n",
      "  ✓ Loaded: #MiddleEastCrisis         - 70 months, max=100\n",
      "  ✓ Loaded: #MENA                     - 70 months, max=100\n",
      "  ✓ Loaded: #FreeMiddleEast           - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 130 months with 3 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "      Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "            #MENA        0.135069            0.062346           69\n",
      "#MiddleEastCrisis        0.004776           -0.069052           69\n",
      "  #FreeMiddleEast        0.004776           -0.069052           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#MENA:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.143\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.142\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.153\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.135\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.153\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.142\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.143\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#MiddleEastCrisis:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.003\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.005\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.003\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.005\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.003\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.005\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.003\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#FreeMiddleEast:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.003\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.005\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.003\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.005\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.003\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.005\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.003\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 5,032\n",
      "  ACLED Fatalities: 2,259\n",
      "  Search Interest:\n",
      "    - #MiddleEastCrisis        : 0/100\n",
      "    - #MENA                    : 62/100\n",
      "    - #FreeMiddleEast          : 0/100\n",
      "\n",
      "October 2023:\n",
      "  ACLED Events: 4,223\n",
      "  ACLED Fatalities: 5,679\n",
      "  Search Interest:\n",
      "    - #MiddleEastCrisis        : 0/100\n",
      "    - #MENA                    : 63/100\n",
      "    - #FreeMiddleEast          : 0/100\n",
      "\n",
      "November 2024:\n",
      "  ACLED Events: 4,206\n",
      "  ACLED Fatalities: 2,124\n",
      "  Search Interest:\n",
      "    - #MiddleEastCrisis        : 0/100\n",
      "    - #MENA                    : 62/100\n",
      "    - #FreeMiddleEast          : 0/100\n",
      "\n",
      "March 2024:\n",
      "  ACLED Events: 3,388\n",
      "  ACLED Fatalities: 1,756\n",
      "  Search Interest:\n",
      "    - #MiddleEastCrisis        : 0/100\n",
      "    - #MENA                    : 63/100\n",
      "    - #FreeMiddleEast          : 0/100\n",
      "\n",
      "December 2023:\n",
      "  ACLED Events: 3,305\n",
      "  ACLED Fatalities: 2,975\n",
      "  Search Interest:\n",
      "    - #MiddleEastCrisis        : 0/100\n",
      "    - #MENA                    : 62/100\n",
      "    - #FreeMiddleEast          : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: middleEast_hashtags_acled_vs_trends.html\n",
      "✓ Saved: middleEast_hashtags_#mena_comparison.html\n",
      "✓ Saved: middleEast_hashtags_#middleeastcrisis_comparison.html\n",
      "✓ Saved: middleEast_hashtags_#freemiddleeast_comparison.html\n",
      "\n",
      "✓ Middle East hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# MIDDLE EAST HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MIDDLE EAST HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "middleEast_acled = acled[\n",
    "    (acled['REGION'] == 'Middle East') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "middleEast_acled['WEEK'] = pd.to_datetime(middleEast_acled['WEEK'])\n",
    "\n",
    "middleEast_acled['month'] = middleEast_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = middleEast_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "middleEast_hashtag_files = {\n",
    "    '#MiddleEastCrisis': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_MiddleEastCrisis.csv',\n",
    "    '#MENA': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_MENA.csv',\n",
    "    '#FreeMiddleEast': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FreeMiddleEast.csv'\n",
    "}\n",
    "\n",
    "print(\"\\nNOTE: Hashtag removed for MENA due to no data.\")\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in middleEast_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Middle East Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Middle East-related Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('middleEast_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: middleEast_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Middle East Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"middleEast_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Middle East hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbe533",
   "metadata": {},
   "source": [
    "#### 2) Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ddfbb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EUROPE HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 94 months\n",
      "  Date range: 2017-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 176,858\n",
      "  Total fatalities: 74,699\n",
      "  ✓ Loaded: #EuropeanSolidarity       - 70 months, max=100\n",
      "  ✓ Loaded: #EU                       - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 94 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "        Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#EuropeanSolidarity       -0.132766            0.009089           69\n",
      "                #EU       -0.290454           -0.381270           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#EuropeanSolidarity:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.141\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.135\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.135\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.133\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.135\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.135\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.141\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#EU:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.229\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.253\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.296\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.290\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.296\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.253\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.229\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 5,123\n",
      "  ACLED Fatalities: 3,696\n",
      "  Search Interest:\n",
      "    - #EuropeanSolidarity      : 0/100\n",
      "    - #EU                      : 37/100\n",
      "\n",
      "May 2025:\n",
      "  ACLED Events: 5,076\n",
      "  ACLED Fatalities: 2,742\n",
      "  Search Interest:\n",
      "    - #EuropeanSolidarity      : 0/100\n",
      "    - #EU                      : 41/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 5,025\n",
      "  ACLED Fatalities: 2,682\n",
      "  Search Interest:\n",
      "    - #EuropeanSolidarity      : 0/100\n",
      "    - #EU                      : 0/100\n",
      "\n",
      "August 2025:\n",
      "  ACLED Events: 4,929\n",
      "  ACLED Fatalities: 2,197\n",
      "  Search Interest:\n",
      "    - #EuropeanSolidarity      : 0/100\n",
      "    - #EU                      : 0/100\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 4,718\n",
      "  ACLED Fatalities: 3,568\n",
      "  Search Interest:\n",
      "    - #EuropeanSolidarity      : 0/100\n",
      "    - #EU                      : 35/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: europe_hashtags_acled_vs_trends.html\n",
      "✓ Saved: europe_hashtags_#europeansolidarity_comparison.html\n",
      "✓ Saved: europe_hashtags_#eu_comparison.html\n",
      "\n",
      "✓ Europe hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# EUROPE HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EUROPE HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "europe_acled = acled[\n",
    "    (acled['REGION'] == 'Europe') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "europe_acled['WEEK'] = pd.to_datetime(europe_acled['WEEK'])\n",
    "\n",
    "europe_acled['month'] = europe_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = europe_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "europe_hashtag_files = {\n",
    "    '#EuropeanSolidarity': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_EuropeanSolidarity.csv',\n",
    "    '#EU': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_EU.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in europe_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'Europe Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining Europe-related Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('europe_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: europe_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'Europe Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"europe_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ Europe hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13280c",
   "metadata": {},
   "source": [
    "#### 3) South Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44901532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SOUTH ASIA HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 190 months\n",
      "  Date range: 2009-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 124,599\n",
      "  Total fatalities: 25,752\n",
      "  ✓ Loaded: #HelpSouthAsia            - 70 months, max=100\n",
      "  ✓ Loaded: #UnifySouthAsia           - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 190 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "    Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#UnifySouthAsia        0.242820            0.325104           69\n",
      " #HelpSouthAsia       -0.160525           -0.093602           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#UnifySouthAsia:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.250\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.249\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.243\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.243\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.243\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.249\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.250\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#HelpSouthAsia:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.172\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.166\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.166\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.161\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.166\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.166\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.172\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "September 2024:\n",
      "  ACLED Events: 2,034\n",
      "  ACLED Fatalities: 197\n",
      "  Search Interest:\n",
      "    - #HelpSouthAsia           : 0/100\n",
      "    - #UnifySouthAsia          : 0/100\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 1,868\n",
      "  ACLED Fatalities: 266\n",
      "  Search Interest:\n",
      "    - #HelpSouthAsia           : 0/100\n",
      "    - #UnifySouthAsia          : 100/100\n",
      "\n",
      "June 2025:\n",
      "  ACLED Events: 1,829\n",
      "  ACLED Fatalities: 262\n",
      "  Search Interest:\n",
      "    - #HelpSouthAsia           : 0/100\n",
      "    - #UnifySouthAsia          : 0/100\n",
      "\n",
      "June 2024:\n",
      "  ACLED Events: 1,756\n",
      "  ACLED Fatalities: 127\n",
      "  Search Interest:\n",
      "    - #HelpSouthAsia           : 0/100\n",
      "    - #UnifySouthAsia          : 0/100\n",
      "\n",
      "August 2024:\n",
      "  ACLED Events: 1,750\n",
      "  ACLED Fatalities: 206\n",
      "  Search Interest:\n",
      "    - #HelpSouthAsia           : 0/100\n",
      "    - #UnifySouthAsia          : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: southAsia_hashtags_acled_vs_trends.html\n",
      "✓ Saved: southAsia_hashtags_#unifysouthasia_comparison.html\n",
      "✓ Saved: southAsia_hashtags_#helpsouthasia_comparison.html\n",
      "\n",
      "✓ South Asia hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# SOUTH ASIA HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SOUTH ASIA HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "southAsia_acled = acled[\n",
    "    (acled['REGION'] == 'South Asia') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "southAsia_acled['WEEK'] = pd.to_datetime(southAsia_acled['WEEK'])\n",
    "\n",
    "southAsia_acled['month'] = southAsia_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = southAsia_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "southAsia_hashtag_files = {\n",
    "    '#HelpSouthAsia': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_HelpSouthAsia.csv',\n",
    "    '#UnifySouthAsia': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_UnifySouthAsia.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in southAsia_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'South Asia Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining South Asia-related Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('southAsia_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: southAsia_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'South Asia Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"southAsia_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ South Asia hashtags analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6991d85",
   "metadata": {},
   "source": [
    "#### 4) Latin America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5851c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipped beacuse both hastags had no data so had to remove the '#'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d77a6a",
   "metadata": {},
   "source": [
    "#### 5) North America"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14f68e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NORTH AMERICA HASHTAGS ANALYSIS\n",
      "================================================================================\n",
      "✓ ACLED Data: 94 months\n",
      "  Date range: 2017-12-01 00:00:00 to 2025-09-01 00:00:00\n",
      "  Total events: 71,250\n",
      "  Total fatalities: 22,446\n",
      "  ✓ Loaded: #SaveNorthAmerica         - 70 months, max=100\n",
      "  ✓ Loaded: #FreedomConvoy2022        - 70 months, max=100\n",
      "\n",
      "✓ Merged dataset: 94 months with 2 search terms\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "       Search Term  Corr w/ Events  Corr w/ Fatalities  Data Points\n",
      "#FreedomConvoy2022        0.019829           -0.037146           69\n",
      " #SaveNorthAmerica       -0.100813           -0.137019           69\n",
      "\n",
      "================================================================================\n",
      "TIME-LAG ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "#FreedomConvoy2022:\n",
      "  Lag -3 months (searches LEAD  ): correlation = +0.016\n",
      "  Lag -2 months (searches LEAD  ): correlation = +0.019\n",
      "  Lag -1 months (searches LEAD  ): correlation = +0.017\n",
      "  Lag +0 months (CONCURRENT     ): correlation = +0.020\n",
      "  Lag +1 months (searches LAG   ): correlation = +0.017\n",
      "  Lag +2 months (searches LAG   ): correlation = +0.019\n",
      "  Lag +3 months (searches LAG   ): correlation = +0.016\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "#SaveNorthAmerica:\n",
      "  Lag -3 months (searches LEAD  ): correlation = -0.107\n",
      "  Lag -2 months (searches LEAD  ): correlation = -0.103\n",
      "  Lag -1 months (searches LEAD  ): correlation = -0.105\n",
      "  Lag +0 months (CONCURRENT     ): correlation = -0.101\n",
      "  Lag +1 months (searches LAG   ): correlation = -0.105\n",
      "  Lag +2 months (searches LAG   ): correlation = -0.103\n",
      "  Lag +3 months (searches LAG   ): correlation = -0.107\n",
      "\n",
      "  → Best correlation at lag +0: -999.000 (CONCURRENT (searches match events))\n",
      "\n",
      "================================================================================\n",
      "KEY PERIODS\n",
      "================================================================================\n",
      "\n",
      "Top 5 Event Spikes:\n",
      "\n",
      "May 2020:\n",
      "  ACLED Events: 4,505\n",
      "  ACLED Fatalities: 410\n",
      "  Search Interest:\n",
      "    - #SaveNorthAmerica        : 0/100\n",
      "    - #FreedomConvoy2022       : 0/100\n",
      "\n",
      "August 2020:\n",
      "  ACLED Events: 1,903\n",
      "  ACLED Fatalities: 296\n",
      "  Search Interest:\n",
      "    - #SaveNorthAmerica        : 0/100\n",
      "    - #FreedomConvoy2022       : 0/100\n",
      "\n",
      "March 2025:\n",
      "  ACLED Events: 1,582\n",
      "  ACLED Fatalities: 365\n",
      "  Search Interest:\n",
      "    - #SaveNorthAmerica        : 0/100\n",
      "    - #FreedomConvoy2022       : 0/100\n",
      "\n",
      "October 2020:\n",
      "  ACLED Events: 1,440\n",
      "  ACLED Fatalities: 284\n",
      "  Search Interest:\n",
      "    - #SaveNorthAmerica        : 0/100\n",
      "    - #FreedomConvoy2022       : 0/100\n",
      "\n",
      "April 2022:\n",
      "  ACLED Events: 1,433\n",
      "  ACLED Fatalities: 297\n",
      "  Search Interest:\n",
      "    - #SaveNorthAmerica        : 0/100\n",
      "    - #FreedomConvoy2022       : 0/100\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Saved: northAmerica_hashtags_acled_vs_trends.html\n",
      "✓ Saved: northAmerica_hashtags_#freedomconvoy2022_comparison.html\n",
      "✓ Saved: northAmerica_hashtags_#savenorthamerica_comparison.html\n",
      "\n",
      "✓ North America hashtags analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# NORTH AMERICA HASHTAGS ANALYSIS: ACLED EVENTS vs GOOGLE TRENDS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NORTH AMERICA HASHTAGS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. FILTER ACLED DATA\n",
    "# ---------------------\n",
    "\n",
    "northAmerica_acled = acled[\n",
    "    (acled['REGION'] == 'North America') & \n",
    "    (acled['WEEK'] >= '2020-01-01')\n",
    "].copy()\n",
    "\n",
    "northAmerica_acled['WEEK'] = pd.to_datetime(northAmerica_acled['WEEK'])\n",
    "\n",
    "northAmerica_acled['month'] = northAmerica_acled['WEEK'].dt.to_period('M').dt.to_timestamp()\n",
    "monthly = northAmerica_acled.groupby('month').agg({\n",
    "    'EVENTS': 'sum',\n",
    "    'FATALITIES': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"✓ ACLED Data: {len(monthly)} months\")\n",
    "print(f\"  Date range: {monthly['month'].min()} to {monthly['month'].max()}\")\n",
    "print(f\"  Total events: {monthly['EVENTS'].sum():,}\")\n",
    "print(f\"  Total fatalities: {monthly['FATALITIES'].sum():,}\")\n",
    "\n",
    "\n",
    "# 2. LOAD GOOGLE TRENDS FILES\n",
    "# ----------------------------\n",
    "northAmerica_hashtag_files = {\n",
    "    '#SaveNorthAmerica': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_SaveNorthAmerica.csv',\n",
    "    '#FreedomConvoy2022': 'data/google_trends_raw/TIER3_HASHTAGS/google_trends_FreedomConvoy2022.csv'\n",
    "}\n",
    "\n",
    "trends_data = {}\n",
    "for name, filepath in northAmerica_hashtag_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        df.columns = ['month', 'value']\n",
    "        df['month'] = pd.to_datetime(df['month'])\n",
    "        df['value'] = df['value'].replace('<1', '0.5')\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        trends_data[name] = df\n",
    "        print(f\"  ✓ Loaded: {name:25s} - {len(df)} months, max={df['value'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ✗ Error loading {name}: {e}\")\n",
    "        \n",
    "\n",
    "# 3. MERGE DATASETS\n",
    "# -----------------\n",
    "merged = monthly.copy()\n",
    "for name, df in trends_data.items():\n",
    "    merged = merged.merge(\n",
    "        df.rename(columns={'value': name}),\n",
    "        on='month',\n",
    "        how='left'\n",
    "    )\n",
    "print(f\"\\n✓ Merged dataset: {len(merged)} months with {len(trends_data)} search terms\")\n",
    "\n",
    "\n",
    "# 4. CORRELATION ANALYSIS\n",
    "# -----------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correlations = []\n",
    "for term in trends_data.keys():\n",
    "    if term in merged.columns:\n",
    "        valid_data = merged[['EVENTS', 'FATALITIES', term]].dropna()\n",
    "        if len(valid_data) > 10:\n",
    "            corr_events = valid_data['EVENTS'].corr(valid_data[term])\n",
    "            corr_fatalities = valid_data['FATALITIES'].corr(valid_data[term])\n",
    "            correlations.append({\n",
    "                'Search Term': term,\n",
    "                'Corr w/ Events': corr_events,\n",
    "                'Corr w/ Fatalities': corr_fatalities,\n",
    "                'Data Points': len(valid_data)\n",
    "            })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Corr w/ Events', ascending=False)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# 5. TIME-LAG ANALYSIS\n",
    "# --------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME-LAG ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_terms = corr_df.head(3)['Search Term'].tolist()\n",
    "\n",
    "for term in top_terms:\n",
    "    print(f\"\\n{term}:\")\n",
    "    valid_data = merged[['EVENTS', term]].dropna()\n",
    "    best_corr = -999\n",
    "    best_lag = 0\n",
    "    \n",
    "    for lag in range(-3, 4):\n",
    "        if lag == 0:\n",
    "            corr = valid_data['EVENTS'].corr(valid_data[term])\n",
    "        elif lag > 0:\n",
    "            if len(valid_data) > lag:\n",
    "                corr = valid_data['EVENTS'].iloc[lag:].corr(valid_data[term].iloc[:-lag])\n",
    "            else:\n",
    "                corr = 0\n",
    "        else:\n",
    "            if len(valid_data) > abs(lag):\n",
    "                corr = valid_data['EVENTS'].iloc[:lag].corr(valid_data[term].iloc[-lag:])\n",
    "            else:\n",
    "                corr = 0\n",
    "        \n",
    "        if abs(corr) > abs(best_corr):\n",
    "            best_corr = corr\n",
    "            best_lag = lag\n",
    "        \n",
    "        direction = \"searches LAG\" if lag > 0 else (\"searches LEAD\" if lag < 0 else \"CONCURRENT\")\n",
    "        print(f\"  Lag {lag:+2d} months ({direction:15s}): correlation = {corr:+.3f}\")\n",
    "    \n",
    "    interpretation = \"REACTIVE (searches follow events)\" if best_lag > 0 else \\\n",
    "                    \"PREDICTIVE (searches precede events)\" if best_lag < 0 else \\\n",
    "                    \"CONCURRENT (searches match events)\"\n",
    "    print(f\"\\n  → Best correlation at lag {best_lag:+d}: {best_corr:+.3f} ({interpretation})\")\n",
    "\n",
    "# 6. KEY PERIODS IDENTIFICATION\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY PERIODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nTop 5 Event Spikes:\")\n",
    "top_spikes = merged.nlargest(5, 'EVENTS')[['month', 'EVENTS', 'FATALITIES'] + list(trends_data.keys())]\n",
    "for idx, row in top_spikes.iterrows():\n",
    "    print(f\"\\n{row['month'].strftime('%B %Y')}:\")\n",
    "    print(f\"  ACLED Events: {row['EVENTS']:,}\")\n",
    "    print(f\"  ACLED Fatalities: {row['FATALITIES']:,}\")\n",
    "    print(f\"  Search Interest:\")\n",
    "    for term in trends_data.keys():\n",
    "        if pd.notna(row[term]):\n",
    "            print(f\"    - {term:25s}: {row[term]:.0f}/100\")\n",
    "\n",
    "# 7. VISUALIZATION\n",
    "# ---------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize data\n",
    "merged_normalized = merged.copy()\n",
    "merged_normalized['EVENTS_norm'] = (merged['EVENTS'] / merged['EVENTS'].max()) * 100\n",
    "merged_normalized['FATALITIES_norm'] = (merged['FATALITIES'] / merged['FATALITIES'].max()) * 100\n",
    "\n",
    "# Reshape for Altair\n",
    "plot_data = []\n",
    "for _, row in merged_normalized.iterrows():\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Events',\n",
    "        'value': row['EVENTS_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['EVENTS']\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'month': row['month'],\n",
    "        'metric': 'ACLED Fatalities',\n",
    "        'value': row['FATALITIES_norm'],\n",
    "        'type': 'Conflict Data',\n",
    "        'raw_value': row['FATALITIES']\n",
    "    })\n",
    "    for term in top_terms:\n",
    "        if term in row and pd.notna(row[term]):\n",
    "            plot_data.append({\n",
    "                'month': row['month'],\n",
    "                'metric': f'Search: {term}',\n",
    "                'value': row[term],\n",
    "                'type': 'Google Trends',\n",
    "                'raw_value': row[term]\n",
    "            })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Main chart\n",
    "chart = alt.Chart(plot_df).mark_line(strokeWidth=2.5, point=True).encode(\n",
    "    x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45)),\n",
    "    y=alt.Y('value:Q', title='Normalized Value (0-100)', scale=alt.Scale(domain=[0, 105])),\n",
    "    color=alt.Color('metric:N', title='Metric', scale=alt.Scale(scheme='tableau10')),\n",
    "    strokeDash=alt.StrokeDash('type:N', title='Data Type',\n",
    "                               scale=alt.Scale(domain=['Conflict Data', 'Google Trends'],\n",
    "                                             range=[[1,0], [5,3]])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "        alt.Tooltip('metric:N', title='Metric'),\n",
    "        alt.Tooltip('value:Q', title='Normalized', format='.1f'),\n",
    "        alt.Tooltip('raw_value:Q', title='Raw Value', format=',.0f')\n",
    "    ]\n",
    ").properties(\n",
    "    width=1400,\n",
    "    height=450,\n",
    "    title={\n",
    "        'text': 'North America Hashtags: ACLED Events vs Google Search Interest (2020-2025)',\n",
    "        'subtitle': 'Examining North America-related Hashtags',\n",
    "        'fontSize': 18,\n",
    "        'subtitleFontSize': 13\n",
    "    }\n",
    ").interactive()\n",
    "\n",
    "chart.save('northAmerica_hashtags_acled_vs_trends.html')\n",
    "print(f\"✓ Saved: northAmerica_hashtags_acled_vs_trends.html\")\n",
    "\n",
    "# Display\n",
    "chart\n",
    "\n",
    "# 8. INDIVIDUAL COMPARISON CHARTS\n",
    "# --------------------------------\n",
    "for term in top_terms:\n",
    "    term_data = merged[['month', 'EVENTS', 'FATALITIES', term]].dropna().copy()\n",
    "    \n",
    "    base = alt.Chart(term_data).encode(\n",
    "        x=alt.X('month:T', title='Month', axis=alt.Axis(format='%b %Y', labelAngle=-45))\n",
    "    )\n",
    "    \n",
    "    events_line = base.mark_line(color='steelblue', strokeWidth=3).encode(\n",
    "        y=alt.Y('EVENTS:Q', title='ACLED Events', axis=alt.Axis(titleColor='steelblue')),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trends_line = base.mark_line(color='red', strokeWidth=3).encode(\n",
    "        y=alt.Y(f'{term}:Q', title=f'Google Trends: {term}',\n",
    "                axis=alt.Axis(titleColor='red'), scale=alt.Scale(domain=[0, 100])),\n",
    "        tooltip=[\n",
    "            alt.Tooltip('month:T', title='Month', format='%B %Y'),\n",
    "            alt.Tooltip('EVENTS:Q', title='Events', format=','),\n",
    "            alt.Tooltip(f'{term}:Q', title='Search Interest', format='.0f')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    term_chart = alt.layer(events_line, trends_line).resolve_scale(\n",
    "        y='independent'\n",
    "    ).properties(\n",
    "        width=1200,\n",
    "        height=400,\n",
    "        title=f'northAmerica Hashtags: ACLED Events vs \"{term}\" Search Interest'\n",
    "    ).interactive()\n",
    "    \n",
    "    filename = f\"northAmerica_hashtags_{term.lower().replace(' ', '_')}_comparison.html\"\n",
    "    term_chart.save(filename)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n✓ North America hashtags analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
